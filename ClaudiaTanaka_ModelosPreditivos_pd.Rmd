---
title:  Projeto da Disciplina de Modelos Preditivos
author: Claudia Tanaka (claudia.tanaka@al.infnet.edu.br)
date:   "Atualizado em `r format(Sys.time(), '%d/%m/%Y')`"

bookdown::html_document2:
  toc: yes
  toc_float: yes
  fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( message=FALSE, warning=FALSE )
options(scipen=999) # "Desliga" notação científica. 

# PACOTES 
library(tidyverse)
library(tidymodels)
tidymodels_prefer()
library(corrr)
library(GGally)

# PRETTY DOC
library(gt)
library(patchwork)

theme_set(theme_light(base_size=9))
theme_update(
  panel.grid.minor = element_blank(),
  panel.grid.major = element_line(colour="gray95"),
  plot.title = element_text(size=10, colour="gray30", face="bold"),
  plot.subtitle = element_text(face='italic', colour="gray50", size=9),
  plot.caption = element_text(colour="gray50", hjust=0, size=8),
  legend.title = element_blank(),
)

# FUNCTIONS
tidyConfMat <- function(df) {
  df |> 
    mutate(
      y = case_when(name=="cell_1_1" ~ 1,
                    name=="cell_2_2" ~ 0,
                    name=="cell_1_2" ~ 1,
                    name=="cell_2_1" ~ 0),
      x = case_when(name=="cell_1_1" ~ 0,
                    name=="cell_2_2" ~ 1,
                    name=="cell_1_2" ~ 1,
                    name=="cell_2_1" ~ 0),
      category = case_when(y==1 & x==0 ~ "TP",
                           y==0 & x==1 ~ "TN",
                           y==0 & x==0 ~ "FN",
                           y==1 & x==1 ~ "FP",
                           .default=NA),
      gg.lbl = paste0(value," (", category, ")" ),
      gg.col = case_when(y==1 & x==0 ~ "darkgreen",
                         y==0 & x==1 ~ "darkgreen",
                         y==0 & x==0 ~ "red",
                         y==1 & x==1 ~ "red",
                         .default=NA)
    )
}

plotConfMat <- function(df) {
  df |> 
    ggplot(aes(x, y)) +
    geom_tile(aes(fill=gg.col), colour="white", alpha=.7) +
    geom_text(aes(label=gg.lbl), size=3) +
    facet_wrap(~model, nrow=1) +
    scale_x_continuous(expand=expansion(mult=c(0,0)), breaks=NULL, position="top") +
    scale_y_continuous(expand=expansion(mult=c(0,0)), breaks=NULL) +
    theme(legend.position = "none") +
    scale_fill_identity() +
    labs(title = "Confusion matrix", 
         x="TRUTH", y="PREDICTION")
}
```

\

Nessa disciplina, aprofundamos nossos conhecimentos em modelos preditivos, tarefa que é extremamente importante para o dia-a-dia de um cientista de dados. Agora iremos validar nosso conhecimento.

Para a realização desse trabalho, será necessário utilizar a plataforma Knime e seus componentes para uso de algoritmos de Machine Learning.

Escolha uma base de dados para realizar esse projeto, onde você utilizará algoritmos de classificação. Essa base necessita ter 4 (ou mais) variáveis de interesse e 2 (apenas 2!) classes (rótulos). Caso você tenha dificuldade para escolher uma base, o(a) professor(a) da disciplina irá designar uma para você.

\

# Ambiente

**No relatório final, anexe um printscreen evidenciando que o Knime está funcionando com os componentes**


![Printscreen do Knime instalado na minha máquina](.imgs/Rstudio.png)


\

```{r}
print(sessionInfo(), locale=FALSE)
```

\

# Base escolhida

**Explique a motivação de uso da base escolhida.**

O objetivo deste projeto é avaliar a propensão ou risco de rotatividade dos clientes de uma empresa de telecomunicações. Isto é fundamental para o negócio de telecomunicações porque muitas vezes é mais caro adquirir novos clientes do que manter os existentes.

Especificamente, nosso projeto fará uma modelagem para a classificação dos clientes entre contratos cancelados (`Churned`) ou não cancelados (\`Renewed\`\`), gerando um modelo final que ajudará a empresa a identificar clientes altamente propensos ao cancelamento de forma que sua área comercial possa atuar especificamente sobre estes clientes.

Adicionalmente, gostaríamos de poder avaliar a importância relativa das variáveis explicativas do modelo final para identificar os fatores mais influenciadores do risco de cancelamento do cliente.

\
Este projeto é baseado em um [conjunto de dados da IBM no Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) com 21 variáveis e mais de 7 mil observações.

```{r}
df0 <- 
  read.csv("_datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv") |> 
  as_tibble() |> 
  rename(Gender=gender, Tenure=tenure) |> 
  mutate(SeniorCitizen = if_else(SeniorCitizen==0, "No", "Yes"),
         # Ordena para que a classificação de referência seja "Churned"= "Yes"
         Churn = factor(Churn, 
                        levels=c("Yes", "No"), 
                        labels=c("Churned", "Renewed"))) |> 
  mutate(across(where(is.character), ~if_else(.x=="", NA, .x)),
         across(where(is.character), as.factor))

dim(df0)
```

\

# Variáveis

**Descreva as variáveis presentes na base. Quais são as variáveis? Quais são os tipos de variáveis (discreta, categórica, contínua)? Quais são as médias e desvios padrões?**

Cada linha representa um cliente e cada coluna contém os seguintes atributos do cliente:

Este conjunto de dados inclui as seguintes 20 variáveis explicativas (features):

-   Quatro variáveis de [dados demográficos]{.underline}:

    -   `Gender` (gênero masculino ou feminino),

    -   `SeniorCitizen` (se é ou não idoso),

    -   `Partner` (se tem ou não parceiro),

    -   `Dependents` (se tem ou não dependentes)

-   Nove variáveis de [serviços assinados]{.underline}:

    -   `PhoneService`,

    -   `MultipleLine`,

    -   `InternetService`,

    -   `OnlineSecurity`,

    -   `OnlineBackup`,

    -   `DeviceProtection`,

    -   `TechSupport`,

    -   `StreamingTV` e

    -   `StreamingMovies`

-   Sete variáveis de [informações da conta do cliente]{.underline}:

    -   `CustomerID`, que é uma chave de identificação do cliente,

    -   `Contract` tipo de contrato - mensal, anual ou bianual,

    -   `PaperlessBilling` se recebe ou não a fatura online,

    -   `PaymentMethod` método de pagamento - Débito automático, Cartão de crédito, cheque eletrônico ou de papel,

    -   `MonthlyCharges` valor da mensalidade,

    -   `TotalCharges` cobrança total incluindo mensalidade e

    -   `Tenure` há quantos meses é cliente

A variável dependente de interesse (target) é o `Churn`, que é uma variável binária. Os clientes são classificados como "Yes" (Churned) ou "No" (Renewed).

```{r}
str(df0)
```

Todas as variáveis são categóricas, exceto a variável numérica discreta `Tenure` (há quantos meses é cliente) e as duas variáveis numéricas contínuas: (1) mensalidade (`MonthlyCharges`); e (2) valor total incluindo mensalidade (`TotalCharges`).

\

## Variáveis categóricas

Olhando as variáveis categóricas e suas frequências:

```{r echo=FALSE}
summarytools::dfSummary(df0 |> select(is.factor), 
                        style="multiline", plain.ascii=F, graph.col=F, valid.col=F) |> 
  knitr::kable()
```

Não há lacunas nas variáveis categóricas.

Todos os `customerID` são distintos e, portanto, essa variável tem baixo valor explicativo e não ajudará a informar a distinção entre clientes Churned (cancelados) vs Renewed (mantidos). Manteremos a variável na base para que a empresa possa analisar clientes específicos a partir das análises do modelo, mas ela não será utilizada como variável explicativa na modelagem.

As variáveis dos serviços assinados deveriam ser biárias (sim/não) pois a informação adicional sobre se tem ou não serviço de internet ou de telefone já está contida nas variáveis `PhoneService` e `InternetService`. Torná-las binárias evitará a redundância.

Seria interessante incluir uma variável que conta quantos serviços o cliente assina, além de ter todos os serviços assinados como variáveis binárias.

\

## Variáveis numéricas

Olhando as variáveis numéricas e suas distribuições:

```{r echo=FALSE}
summarytools::dfSummary(df0 |> select(is.numeric), 
                        style="multiline", plain.ascii=F, graph.col=F, valid.col=F) |> 
  knitr::kable()
```

Há 11 observações com lacunas na variável `TotalCharges`.

\

## Preprocessamento

Apenas 11 observações entre as 7.043 têm dados faltantes (lacunas) e todas com clientes que mantiveram suas assinaturas `Churn = Renewed`, que é a classe majoritária (73% das observações). Portanto, o impacto nos padrões do segmento de clientes retidos é muito pequeno e optamos por não aplicar uma metodologia de imputação no preprocessamento, mas apenas excluir estas observações da base.

Nota-se que em uma eventual implementação do modelo para fazer predições, observações com lacunas não terão previsões se o modelo precisar da variável explicativa que estiver faltando. O volume de observações com lacunas a serem alimentadas no modelo em produção sempre tem que ser monitorado (independente de como dados faltantes foram tratados na base usada para treinar o modelo). Se houver um aumento das observações com lacunas a ponto de impactar as previsões, será necessário decidir como ajustar o modelo para lidar com isso.

No nosso projeto, como o objetivo principal é identificar clientes altamente propensos ao cancelamento para que a área comercial possa atuar especificamente sobre estes clientes, julgo que a exclusão desse pequeno volume de observações com lacunas não terá grande impacto na ação da empresa - haverá volume suficiente de clientes de alto risco para a área comercial atuar se a proporção de dados faltantes permanecer baixa nas novas observações. Além disso, esse volume reduzido de dados faltantes especificamente sobre clientes retidos não comprometerá a análise sobre os fatores que levam ao cancelamento pois não provocam alteração significativa no balanceamento das classes da variável target.

A seguir as transformações aplicadas sobre toda a base, antes de preparar para a modelagem:

```{r}
df1 <- df0 |>
  # Omite obs com lacunas
  na.omit() |>
  
  mutate(
    # Torna as variáveis Yes/No/etc binárias - apenas Yes/No
    across(c(MultipleLines, OnlineSecurity:StreamingMovies), ~if_else(.x=="Yes", .x, "No")),
    # Fatoriza todas as variáveis categóricas
    across(is.character, as.factor)
  ) |> 
  # Cria coluna que conta quantos serviços de internet foram assinados 
  # por cada cliente
  rowwise() |> 
  mutate(n.internet = sum(c_across(OnlineSecurity:StreamingMovies)=="Yes")) |>
  ungroup()

str(df1)
```

\

## EDA

::: {.alert .alert-danger}
-   Outliers?\
-   Categorização das variáveis numéricas?\
-   Correlações entre as variáveis?\
-   Hipóteses sobre as variáveis mais explicativas?\
:::

\

### Variáveis demográficas

A proporção de clientes por gênero e se têm ou não parceiros é bem balanceada. A maioria dos clientes não são idosos e não têm dependentes.

```{r echo=FALSE, fig.width=4, fig.asp=.7}
df1 |> select(Gender:Dependents) |> 
  pivot_longer(cols=Gender:Dependents, values_to="class", names_to="variable") |>
  summarise(value=n(), .by=c(variable, class)) |>
  mutate(pct = value/sum(value), .by=variable) |> 
  mutate(
    class = factor(class, levels=c("No","Yes", "Female", "Male")),
    class.lbl = if_else(pct > .2, paste0(class, " (", scales::percent(pct,accuracy=1), ")"), class),
    variable = forcats::fct_rev(factor(variable, levels=c("Gender", "SeniorCitizen", 
                                                 "Partner", "Dependents")))
    ) |> 
  ggplot(aes(y=variable, x=pct, fill=class, group=class)) +
  geom_col(color="white") +
  geom_text(aes(label=class.lbl, group=class), 
            position = position_fill(.5), check_overlap=T, size=3) +
  scale_x_continuous(expand=expansion(mult=c(0,.0)), breaks=NULL) +
  theme(panel.grid.major.x=element_blank(), legend.position="none") +
  labs(title="Variaveis demograficas", 
       subtitle=glue::glue("n = {nrow(df1)}"), x=NULL, y=NULL)
```

\

A proporção de `Churn` nas variáveis demográficas leva a crer que a variável `Gender` não será uma variável explicativa relevante para a propensão ao cancelamento porque a proporção de cancelamento é similar entre gêneros.

Clientes que são `SeniorCitizens`, clientes que não têm parceiros e clientes sem dependentes parecem ter maior propensão ao cancelamento.

```{r bidemog, echo=FALSE, fig.width=4, fig.height=4, fig.cap="*Gráfico das variáveis demográficas versus Churn.*"}
df1 |> 
  select(Gender:Dependents, Churn) |> 
  ggbivariate(
    outcome="Churn", 
    rowbar_args = list(colour = "white",
                       size = 3,
                       label_format = scales::label_percent(accurary=1)),
    title = "Churn x Variaveis demograficas"
  ) +
  theme(panel.spacing=unit(.5, "lines"), legend.position="bottom") +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(subtitle=glue::glue("n = {nrow(df1)}"))
```

\

### Serviços contratados

```{r include=FALSE}
v.comInternetTelefone <- round(nrow(filter(df1,PhoneService=="Yes",InternetService!="No"))/nrow(df1)*100)
v.telefonia <- round(nrow(filter(df1,PhoneService=="Yes"))/nrow(df1)*100)
v.multiplelines <- round(nrow(filter(df1,MultipleLines=="Yes"))/nrow(df1)*100)
v.internetService <- round(nrow(filter(df1,InternetService=="Fiber optic"))/nrow(df1)*100)
v.dsl <- round(nrow(filter(df1,InternetService=="DSL"))/nrow(df1)*100)
v.n.internet <- round(nrow(filter(df1,InternetService!="No" & n.internet > 0)) / nrow(filter(df1,InternetService!="No"))*100)
v.n.streaming <- round(df1 |> filter(StreamingTV=="Yes"|StreamingMovies=="Yes") |> nrow() / nrow(df1)*100)
```


Sendo uma empresa de telecomunicações, todos os clientes têm `PhoneService` e/ou `InternetService` contratado. Especificamente verifica-se que a maioria (`r v.comInternetTelefone`%) dos clientes têm tanto internet quanto telefonia.

Em relação ao padrão de serviços de telefonia contratados, como `r v.telefonia`% dos clientes têm telefonia e `r v.multiplelines`% dos clientes têm múltiplas linhas, quase a metade dos clientes de telefonia tem mais de uma linha.

Clientes em fibra ótica são um pouco mais frequentes que clientes com DSL. Dos clientes que assinam internet com a empresa, `r v.internetService`% contrataram fibra ótica e `r v.dsl`% contrataram DSL.

Verifica-se no dataset também que `r v.n.internet`% dos clientes com internet têm algum tipo de serviço adicional contratado. Como se vê na Figura abaixo, a maioria dos serviços adicionais não chega a ser contratado por metade dos clientes com internet, exceto os serviços de *streaming*.

Os serviços adicionais mais frequentes são `StreamingTV` e `StreamingMovies`. De fato, dos clientes com serviços de internet, verifica-se que `r v.n.streaming`% contratam TV ou Movies ou ambos. Seria interessante conversar com a equipe de negócios para checar a diferença entre esses dois serviços e verificar se faria sentido juntar os clientes destes serviços em uma única variável, caso isso melhorasse a performance do modelo em produção.

```{r echo=FALSE, fig.width=5, fig.asp=.7}
df1 |> select(PhoneService:StreamingMovies) |> 
  pivot_longer(cols=PhoneService:StreamingMovies, values_to="class", names_to="variable") |> 
  summarise(value=n(), .by=c(variable, class)) |>
  mutate(pct = value/sum(value), .by=variable) |> 
  mutate(
    class.lbl = if_else(pct>.2, paste0(class," (",scales::percent(pct,accuracy=1),")"), class),
    variable = forcats::fct_rev(
      factor(variable, levels=c("PhoneService", "MultipleLines", "InternetService", 
                                "OnlineSecurity", "OnlineBackup", "DeviceProtection",
                                "TechSupport", "StreamingTV", "StreamingMovies"))
    )) |>
  ggplot(aes(y=variable, x=pct, fill=class, group=class)) +
  geom_col(color="white") +
  geom_text(aes(label=class.lbl, group=class), 
            position = position_fill(.5), check_overlap=T, size=3) +
  scale_x_continuous(expand=expansion(mult=c(0,.0)), breaks=NULL) +
  theme(panel.grid.major.x=element_blank(), legend.position="none") +
  labs(title="Servicos contratados", 
       subtitle=glue::glue("n = {nrow(df1)}"), x=NULL, y=NULL)
```

\


A contratação de serviços de `PhoneService` e talvez `MultipleLines` parece ter pouca diferença em termos de proporção de `Churn`, levantando a hipótese de baixa relevância explicativa dessas variáveis para nossa variável target.

Já a contratação de `InternetService` parece ser uma variável mais relevante para explicar a propensão ao cancelamento. Clientes com serviços de internet - seja DSL ou fibra ótica - são significamente mais propensos ao cancelamento.

```{r chrnServices, echo=FALSE, fig.asp=.9, fig.width=4, fig.cap="*Gráfico das variáveis de serviços assinados versus Churn.*"}
ggbivariate(df1 |> select(PhoneService:InternetService, Churn), 
            outcome="Churn", 
            rowbar_args = list(colour = "white",
                               size = 3,
                               label_format = scales::label_percent(accurary=1)),
            # types = list(comboVertical="autopoint"),
            title = "Churn x Serviços assinados (parte 1)") +
  theme(panel.spacing=unit(.5, "lines"), legend.position="bottom") +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(subtitle=glue::glue("n = {nrow(df1)}"))
```

\

Clientes com serviços de internet que não contratam serviços adicionais parecem ter maior propensão ao cancelamento exceto quando o serviço adicional é `StreamingTV` ou `StreamingMovies`.

```{r chrnInternet, echo=FALSE, fig.asp=1.3, fig.width=4, fig.cap="*Gráfico das variáveis de serviços de internet assinados versus Churn.*"}
ggbivariate(df1 |> select(OnlineSecurity:StreamingMovies, Churn), 
                  outcome="Churn", 
                  rowbar_args = list(colour = "white",
                                     size = 3,
                                     label_format = scales::label_percent(accurary = 1)),
                  # types = list(comboVertical="autopoint"),
                  title = "Churn x Serviços adicionais de internet") +
  theme(panel.spacing=unit(.6, "lines"), legend.position="none") +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(subtitle=glue::glue("n = {nrow(df1)}"))
```

É interessante notar com relação aos serviços contratados que a base de dados já está estruturada como se cada serviço fosse uma variável binária (sim/não). Portanto, não é necessário fazer a transformação de variáveis categóricas em numéricas usando variáveis *dummy* ou *one-hot-encoding*.

\

### Informações da conta

A maioria dos clientes tem contrato renovado mensalmente (`r round(nrow(filter(df1,Contract=="Month-to-month"))/nrow(df1)*100)`%) e dispensou o recebimento da fatura em papel (`r round(nrow(filter(df1,PaperlessBilling=="Yes"))/nrow(df1)*100)`%). A maioria (`r round(nrow(filter(df1,PaymentMethod %in% c("Electronic check", "Mailed check")))/nrow(df1)*100)`%) dos clientes faz pagamentos por cheque enviado pelo correio ou por meio eletrônico -- ou seja, não adota uma forma de pagamento automática.

```{r echo=FALSE, fig.width=6, fig.asp=.45}
df1 |> select(Contract:PaymentMethod) |> 
  pivot_longer(cols=c(Contract:PaymentMethod), values_to="class", names_to="variable") |> 
  summarise(value=n(), .by=c(variable, class)) |>
  mutate(pct = value/sum(value), .by=variable) |>
  mutate(
    class = factor(class, 
                   levels=c("Month-to-month", "One year", "Two year",
                            "No","Yes", 
                            "Bank transfer (automatic)", "Credit card (automatic)",
                            "Electronic check", "Mailed check"),
                   labels=c("Month-to-month", "One year", "Two year",
                            "No","Yes", 
                            "Bank transfer\n", "Credit card\n",
                            "Electronic check\n", "Mailed check\n")),
    class.lbl = if_else(pct>.2, paste0(class," (",scales::percent(pct,accuracy=1),")"), class),
    variable= factor(variable, levels=c("PaymentMethod", "PaperlessBilling", "Contract"))
  ) |> 
  ggplot(aes(y=variable, x=pct, fill=class, group=class)) +
  geom_col(color="white") +
  geom_text(aes(label=class.lbl, group=class), 
            position = position_fill(.5), check_overlap=T, size=3) +
  scale_x_continuous(expand=expansion(mult=c(0,.0)), breaks=NULL) +
  theme(panel.grid.major.x=element_blank(), legend.position="none") +
  scale_fill_brewer(palette="Set3") +
  labs(title="Informações da conta", 
       subtitle=glue::glue("n = {nrow(df1)}"), x=NULL, y=NULL)
```

Nas variáveis categóricas de informações da conta parece haver diferenças marcantes na proporção de `Churn`. A variável `Contract` parece ser muito relevante para explicar a propensão ao cancelamento, com a maioria dos clientes `Churned` estando em contratos que se renovam mensalmente, o que era de se esperar.

Clientes que dispensaram o recebimento de faturas em papel são mais propensos a cancelamento.

Em `PaymentMethod`, clientes que adotam pagamento por cheque eletrônico são os mais propensos ao cancelamento. A proporção de clientes cancelados com pagamento automático via cartão de crédito ou transferência bancária é muito similar. Seria interessante conversar com a equipe de negócios para checar se há relevância nas diferenças entre esses dois tipos de pagamento para o cancelamento de clientes e verificar se faria sentido juntar esses clientes em uma classe única de pagamentos automáticos, caso isso traga benefícios para a performance do modelo em produção.

```{r chrnAccount, echo=FALSE, fig.asp=1.5, fig.width=5, fig.cap="*Gráfico das variáveis de informações da conta versus Churn.*"}
ggbivariate(df1 |> select(c(Contract:TotalCharges, Tenure), Churn), 
            outcome="Churn", 
            rowbar_args = list(colour = "white",
                               size = 3,
                               label_format = scales::label_percent(accurary = 1)),
            # types = list(comboVertical="autopoint"),
            title = "Churn x Informações da conta") +
  theme(panel.spacing=unit(.6, "lines"), legend.position="none") +
  scale_fill_brewer(palette="Set1") +
  scale_color_brewer(palette="Set1") +
  labs(subtitle=glue::glue("n = {nrow(df1)}"))
```

O boxplot aponta concentrações diferentes em relação ao `Churn` para as três variáveis numéricas `MonthlyCharges`, `TotalCharges` e `Tenure`. A faixa de valores entre mínimo e máximo de cada variável é similar para clientes cancelados (`Churned`) e clientes retidos (`Renewed`). Nas três variáveis os clientes cancelados aparentam ter uma distribuição mais concentrada em um intervalo menor que clientes retidos.

No caso de `TotalCharges` essa maior concentração além de ocorrer em um intervalo menor, ocorre em valores mais baixos da escala comparada à distribuição dos clientes retidos, de forma que os valores mais altos se apresentam como valores atípicos (fora dos limites do intervalo interquartílico calculado para uma distribuição normal).

`MonthlyCharges`, que corresponde à parcela do valor pago que decorre de assinaturas mensais, tem uma dispersão bem mais limitada que `TotalCharges` em termos de valores máximos atingidos. A distribuição de `MonthlyCharges` para clientes cancelados està concentrada em um intervalo menor, porém de valores mais elevados que a distribuição dos clientes retidos.

`Tenure` (há quantos meses é cliente) também tem uma distribuição concentrada em um intervalo menor para clientes cancelados que clientes retidos e esse intervalo também abrange valores mais baixos.

Como pode-se observar na Figura \@ref(fig:histogramas) e nos boxplots da Figura \@ref(fig:chrnAccount), nenhuma das variáveis numéricas parece ter distribuição normal e nem valores extremos.

```{r histogramas, echo=FALSE, fig.cap="*Histograma das variáveis numéricas*", fig.width=8, fig.asp=.5}
df1 |> select(Tenure, MonthlyCharges, TotalCharges, Churn) |> 
  pivot_longer(is.numeric) |> 
  mutate(name = factor(name, levels=c("Tenure", "MonthlyCharges", "TotalCharges"),
                       labels=c("Tenure (months)", "Monthly charges", "Total charges"))) |>
  mutate(mean = mean(value), 
         median = median(value), 
         q1 = quantile(value, 0.25), 
         q3 = quantile(value, 0.75), 
         .by=c(name, Churn)) |>
  ggplot(aes(value)) +
  geom_histogram(bins=30, color="white", fill="slategray") +
  facet_grid(cols=vars(name), rows=vars(Churn), scales="free") +
  # Linhas verticais para média, mediana, q1 e q3
  geom_vline(aes(xintercept=mean, color="média"), linewidth=.7, show.legend=T) +
  geom_vline(aes(xintercept=median, color = "mediana"), linewidth=.7, show.legend=T) +
  geom_vline(aes(xintercept=q1, color="q1/q3"), linewidth=.7, show.legend=T) +
  geom_vline(aes(xintercept=q3, color="q1/q3"), linewidth=.7, show.legend=T) +
  # Estetica
  scale_y_continuous(expand=expansion(mult=c(0,.05))) +
  scale_color_manual(name="", values=c("média"="black", "mediana"="blue", "q1/q3"="red")) +
  theme(legend.position="bottom", panel.grid.major.x=element_blank()) +
  labs(title = "Histogramas: Churn e Variáveis numéricas",
       x = NULL, y = "Frequência")
```

### Correlações

\

Todas as correlações entre variáveis numéricas e a variável target `Churn` são fracas, o que sugere que nenhuma variável numérica isoladamente é um bom preditor de `Churn`. A variável `Tenure` é a que tem a correlação mais forte com `Churn`, mas ainda assim é uma correlação baixa.

```{r fig.asp=.5, fig.width=5}
suppressMessages(
  print(
    df1 |> select(is.numeric, Churn) |> 
      mutate(Churn = as.integer(Churn)) |>
      
      # Usa o pacote corrr para calcular a correlação de Spearman
      correlate(method="spearman") |> 
      focus(Churn) |>
      mutate(term = fct_reorder(term, Churn)) |>
      ggplot(aes(y=term, x=Churn)) +
      geom_col(fill="cadetblue") +
      geom_text(aes(x=Churn+.08*sign(Churn),label=round(Churn,2)), size=3) +
      scale_x_continuous(expand=expansion(mult=c(.0,.0)), limits=c(-1,1)) +
      labs(title="Correlação entre variáveis numéricas e Churn", 
           subtitle="Coeficiente de Spearman", 
           x="Correlação para Churn (binary T/F)", y=NULL)
  )
)
```

\

As três variáveis numéricas têm correlações estatisticamente significativas e positivas entre si. A correlação entre `Tenure` e `TotalCharges` é a mais forte. Clientes com mais meses de assinatura dos serviços tendem a ser aqueles que têm valor total (incluindo, mas não limitado a mensalidades) mais alto.

A correlação entre `TotalCharges` e `MonthlyCharges` também tem intensidade moderada a forte, sendo a correlação na classe de clientes cancelados mais fraca que na de clientes retidos.

```{r fig.width=4, fig.asp=.7}
suppressMessages(
  print(
    df1 |> 
      select(is.numeric) |> 
      correlate(method="spearman") |> 
      rearrange(absolute=T) |>
      shave() |>
      rplot(shape=15, print_cor=T) +
      theme_bw(base_size=9) +
      theme(panel.grid.major = element_line(colour = "gray92", size = 0.1),
            plot.title = element_text(size = 10, colour = "gray30", face = "bold"),
            plot.subtitle = element_text(face = 'italic', colour = "gray50", size=9),
            plot.caption = element_text(colour = "gray50", hjust=0, size=8)) +
      labs(title="Correlação entre preditores numéricos", 
           subtitle="Coeficiente de Spearman")
  )
)
```


```{r include=FALSE}
rm(df0)
```


\

# Overfitting

**Em relação à base escolhida:**

## Validação cruzada {#validacao-cruzada}

**(1) Você irá comparar alguns modelos para prever as classes. Descreva como a validação cruzada pode ser usada para comparar modelos de maneira justa. Descreva o procedimento e como uma métrica final é calculada.**

O [Capítulo 10. Resampling for Evaluating Performance](https://www.tmwr.org/resampling#resampling) do livro Tidy Modeling with R ([Kuhn e Silge 2023]()#references) explica os fundamentos da validação cruzada.

Algumas técnicas de modelagem (como regressão linear/logística, análise discriminante e outros) são considerados modelos de alto viés pois não são altamente adaptáveis aos tipos de padrões que podem ser encontrados nos dados. Porém muitos modelos "*black-box*" (de difícil interpretação, como redes neurais, random forest) têm baixo viés, o que significa que podem reproduzir relacionamentos altamente complexos de vários tipos de padrões encontrados em um conjunto de dados.

Para um modelo de baixo viés, o alto grau de capacidade preditiva pode resultar no modelo reproduzir quase exatamente os dados do conjunto de treino. Um modelo de baixo viés treinado em certo conjunto de dados sempre fornecerá previsões perfeitas para estes dados de treino, mas pode não funcionar tão bem para novas observações. Isso é conhecido como *overfitting*. Testar as projeções no próprio conjunto de treino sempre resulta em uma estimativa artificialmente otimista de performance e aumenta as chances que o modelo não tenha uma boa performance em novas observações.

Uma solução popular para evitar a precisão superotimista das projeções (*overfitting*) é avaliar o desempenho não nos dados usados para construir o modelo, mas sim em uma amostra dos dados reservada à parte à qual o modelo não seja exposto durante sua construção – ou seja, uma separação dos dados em subconjunto de treino e subconjunto de teste.

A criação de uma amostra reservada pode ser obtida de várias maneiras, a mais comumente usada sendo a partição aleatória da amostra em conjuntos de treino e teste por métodos de reamostragem. Métodos de reamostragem são sistemas de simulação empírica que emulam o processo de usar alguns dados para treino e dados diferentes para teste. A maioria dos métodos de reamostragem são iterativos, o que significa que esse processo é repetido várias vezes. O diagrama na Figura a seguir ilustra como os métodos de reamostragem geralmente operam.

![Figura 4.1 Esquema de particionamento de dados com reamostragem (Khun e Silge 2023).](.imgs/Resampling.png){#fig4-1 width="500"}

\
A reamostragem é feita somente no conjunto de treino, como se vê na Figura [4.1](#fig4-1). O conjunto de teste não é utilizado. Para cada iteração da reamostragem, os dados são reparticionados em duas sub-amostras:

-   O modelo é treinado com o dataset de [análise]{.underline} (*Analysis*)

-   O modelo é avaliado sobre o dataset de [avaliação]{.underline} (*Assessment*)

Essas duas sub-amostras são análogas aos conjuntos de treino e teste. A terminologia de [análise]{.underline} e [avaliação]{.underline} visa evitar confusão com a divisão inicial dos dados em treino e teste. Esses conjuntos de reamostragem (resample 1, resample 2, ...) são mutuamente exclusivos. O esquema de particionamento usado para criar os conjuntos de análise e avaliação é geralmente a característica definidora do método de reamostragem.

Suponha que sejam feitas 20 iterações de reamostragem. Isso significa que 20 modelos separados são ajustados nos conjuntos de análise e os conjuntos de avaliação correspondentes produzem 20 conjuntos de estatísticas de desempenho. A estimativa final de desempenho para o modelo seria a média das 20 estatísticas de desempenho. Essa média tem potencial de generalização muito alto e é muito superior a estimativas feitas sem particionamento dos dados.

Um método de reamostragem muito utilizado, especialmente com amostras pequenas de dados, é a validação cruzada. Embora haja uma série de variações, o método de validação cruzada mais comum é a validação cruzada [*V-fold*]{.underline}. Os dados são particionados aleatoriamente em $V$ sub-amostras de tamanho aproximadamente igual (as sub-amostras são chamadas de *"folds"*).

A título de ilustração, $V=3$ é mostrado na Figura [4.2](#fig4-2) para um conjunto de dados de treino de 30 observações com alocações aleatórias dos folds. O número dentro dos símbolos identifica a observação. A cor e formato dos símbolos representa a sub-amostra ou fold escolhido aleatoriamente.

![Figura 4.2 Esquema de validação cruzada 3-fold (Khun e Silge 2023).](.imgs/CrossValidationExample.png){#fig4-2 width="350"}

\

Para validação cruzada 3-fold, as três iterações de reamostragem são ilustradas na Figura [4.3](#fig4-3). Para cada iteração, um fold é mantido para teste e os folds restantes são usados para treinar o modelo. Esse processo continua para cada fold, de modo que três modelos são gerados que produzem três conjuntos de estatísticas de performance.

![Figura 4.3 Esquema de validação cruzada 3-fold (Khun e Silge 2023).](.imgs/CrossValidationAplicationExample.png){#fig4-3 width="400"}

\

Quando $V = 3$, os conjuntos de análise são 2/3 do conjunto de treino e cada conjunto de avaliação é um 1/3. A estimativa final de reamostragem calcula a média das estatísticas de performance de cada uma das sub-amostras. Usar $V = 3$ é bom para ilustrar a mecânica da validação cruzada, mas é ruim na prática porque é muito pequeno para gerar estimativas confiáveis. O Teorema do Limite Central sugere que a média de várias estatísticas de desempenho de modelos ajustados em diferentes sub-amostras de dados tende a ter uma distribuição normal. Isso significa que quanto mais sub-amostras forem usadas, mais confiável será a estimativa da média.

Na prática, os valores de V são mais frequentemente $5$ ou $10$; geralmente prefere-se [**validação cruzada 10-fold**]{.underline} como padrão porque a parcela de observações usada na análise ou treino será grande o suficiente para bons resultados na maioria dos casos.

Há variações na aplicação de validações cruzadas, como por exemplo a [validação cruzada com repetição]{.underline}, que cria $R$ repetições de uma validação cruzada V-fold e a [validação cruzada "*leave-one-out"*]{.underline} (LOOCV), que é um caso especial de validação cruzada V-fold com $V = n$, onde $n$ modelos são treinados com $n-1$ observações e cada modelo projeta a observação excluida (técnica utilizada quase exclusivamente quando há amostras muito pequenas de dados). A [validação cruzada de Monte Carlo]{.underline} é uma variação em que a proporção dos dados é determinada aleatoriamente a cada fold. Isso resulta em conjuntos de avaliação que não são mutuamente exclusivos.

Há também outras técnicas de reamostragem, como ["bootstrapping"]{.underline} e também maneiras de testar os modelos em treinamento, como particionar os dados em datasets de validação/treino/teste antes de começar a modelagem.

\

## Balanceamento de classes

**(2) A base se encontra com as classes balanceadas? Cite uma maneira resolver no caso das classes estarem desbalanceadas.**

Neste conjunto de dados de mais de 7.000 clientes, `r scales::percent(nrow(filter(df1, Churn=="Churned"))/nrow(df1), accuracy=.1)` deles cancelaram os serviços no último mês. A variável de interesse `Churn` está desbalanceada, portanto será necessário:

-   Estratificar o split dos datasets de treino/teste para assegurar que preservem a proporção de classes do `Churn`

-   Utilizar técnicas de balanceamento de classes, como a [subamostragem aleatória]{.underline} (*undersampling*) ou [sobreamostragem aleatória]{.underline} (*oversampling*), ou ainda técnicas de [geração sintética de dados]{.underline} como o [SMOTE]{.underline} (Synthetic Minority Over-sampling Technique) para balancear as classes do conjunto de dados de treino antes de fazer o ajuste do modelo.


\

Finaliza preprocessamento da base e separa datasets de treino/teste para modelagem

```{r}
set.seed(888)
df1_split <- rsample::initial_split(df1, prop=.75, strata=Churn)
df1_split
```

```{r}
df1_train <- training(df1_split)
df1_test <- testing(df1_split)

str(df1_train)
```


```{r}
df1_train |> 
  summarise(n=n(), .by=Churn) |>
  mutate(prop = n/sum(n))
```



\

# Técnicas de modelagem

**Qual a diferença entre uma regressão linear e a regressão logística?**

Em resumo, a regressão linear é um método de modelagem de dados utilizado para prever uma variável contínua a partir de uma relação linear estimada entre uma variável target e uma ou mais variáveis explicativas. A regressão logística é um caso específico de um modelo linear generalizado (*generalized linear model* -- GLM) desenvolvido para estender a aplicação da regressão linear a um contexto em que se deseje prever uma variável categórica binária (sim/não, 0/1, evento/não evento).

Assim, apesar de ambos serem modelos lineares, a principal diferença entre os dois métodos é que a regressão linear é utilizada para prever variáveis numéricas contínuas, enquanto a regressão logística é utilizada para prever variáveis categóricas binárias.

\
Mais especificamente, com base nos capítulos sobre Regressão Linear simples, Regressão Linear multivariável e Regressão Logística do livro *Practical Statistics for Data Scientists* de [Bruce et al (2020)](#references):

A [**regressão linear simples**]{.underline} @ref(eq:reg-linear) fornece um modelo da relação entre a magnitude de uma variável e a de uma segunda – por exemplo, à medida que X aumenta, Y também aumenta. Ou à medida que X aumenta, Y diminui. Coeficiente de correlação é outra forma de medir como duas variáveis estão relacionadas. A diferença é que enquanto a correlação mede a força de uma associação entre duas variáveis, a regressão quantifica a natureza da relação.

A regressão linear simples @ref(eq:reg-linear) estima quanto Y mudará quando Y mudar em um determinado valor. Com o coeficiente de correlação, as variáveis X e Y são intercambiáveis. Com a regressão, tentamos prever a variável Y a partir de X usando uma relação linear (ou seja, uma linha):

$$
\begin{equation}
Y = \beta_0 + \beta_1 X
(\#eq:reg-linear)
\end{equation}
$$

O símbolo $\beta_0$ é a constante que determina a interseção com o eixo Y se X fosse igual a zero, e o símbolo $\beta_1$ é o coeficiente da inclinação de X. A variável Y é conhecida como variável de saída, variável *target* ou variável dependente, pois depende de X. A variável X é conhecida como variável explicativa, *feature* ou variável independente.

Considerando o gráfico de dispersão na Figura \@ref(fig:dispersao1) que mostra a largura da pétala de um tipo de flor (`Petal.Width`) versus o comprimento da sua pétala, pode-se visualizar como a largura está relacionada ao comprimento das pétalas. Parece que quanto maior o comprimento, maior a largura.

```{r dispersao1, echo=FALSE, fig.cap="*Gráfico de dispersão Sepal.Length x Sepal.Width*", fig.width=5, fig.asp=.7}
iris |> 
  filter(Species == "versicolor") |>
  ggplot(aes(x=Petal.Length, y=Petal.Width)) +
  geom_point() +
  labs(title = "Gráfico de dispersão Sepal.Length x Sepal.Width",
       subtitle = "Iris dataset")
```

\

A regressão linear simples tenta encontrar a “melhor” linha reta ou a linha reta mais ajustada para prever a variável target Y=`Petal.Width` em função da feature X=`Petal.Length`:

$$
Petal.Width = \beta_0 + \beta_1 Petal.Length
$$\

A linha de regressão deste modelo é a linha azul exibida na Figura \@ref(fig:dispersao2).

```{r dispersao2, echo=FALSE, fig.cap="*Gráfico de dispersão Sepal.Length x Sepal.Width com regressão linear simples*", fig.width=5, fig.asp=.7}
#ggplot needs a dataframe
dat <- iris |> filter(Species == "versicolor")
fit <- lm(Petal.Width~Petal.Length,data=dat)

#add predicted y for each x, to enable segment drawing
dat$pred <- predict(fit, dat)

ggplot(dat, aes(x=Petal.Length,y=Petal.Width))+
  geom_abline(intercept=coefficients(fit)[1],slope=coefficients(fit)[2], 
              color="blue", linewidth=1, linetype="twodash") +
  geom_segment(aes(x=Petal.Length,xend=Petal.Length,y=Petal.Width,yend=pred),
               color="red", size=.7) +
  geom_point(size=2) + 
  labs(title = "Gráfico de dispersão Sepal.Length x Sepal.Width",
       subtitle = "Iris dataset")
```


```{r include=FALSE}
rm(fit, dat); gc()
```


\

É importante notar que a regressão apenas estima a variável target em função da feature explicativa com base nos dados disponíveis. Não há na regressão inferência sobre relação de causa/efeito entre as variáveis (se uma causa a outra ou vice-versa ou se apenas ocorrem juntas).

Como se vê na figura, em geral os dados não caem exatamente na linha reta que foi estimada pela regressão. Então a equação dessa linha de regressão deve incluir um termo de erro explícito que representa essas diferenças conhecidas como resíduos, representadas na Figura \@ref(fig:5-2) como distâncias em vermelho entre os pontos observados e a linha azul estimada. Além disso, entre os estatísticos convenciona-se denotar os valores ajustados ou valores estimados por $\hat{Y}$ (Y com um chapéu), assim como nos coeficientes e no resíduo. Isso indica que os coeficientes e o resíduo também são estimados (não conhecidos) e essa estimativa inclui incerteza, enquanto o valor verdadeiro (sem o chapéu) seria exato:

$$
\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1} X_i + \hat{\epsilon}_i
$$

A linha de regressão é ajustada de modo a minimizar a soma dos quadrados dos resíduos, ou seja, a diferença entre os valores reais e os valores previstos. A linha de regressão é a estimativa que minimiza a soma dos valores residuais quadrados, também chamada de soma residual dos quadrados (residual sum of squares) ou RSS:

$$
\begin{equation}
RSS = \sum_{i=1}^{n} (Y_i - \hat{Y_i})^2 = \sum_{i=1}^{n} (Y_i - \hat{\beta_0} - \hat{\beta_1} X_i)^2
(\#eq:rss)
\end{equation}
$$

As estimativas de $\beta_0$ e $\beta_1$ são os valores que minimizam o RSS \@ref(eq:rss). O método de minimizar a soma dos resíduos quadrados RSS é denominado regressão de mínimos quadrados ou regressão de mínimos quadrados ordinários (OLS - ordinary least squares). É frequentemente atribuído a Carl Friedrich Gauss, o matemático alemão, mas foi publicado pela primeira vez pelo matemático francês Adrien-Marie Legendre em 1805.

\
Quando existem várias variáveis explicativas, a equação é simplesmente estendida para acomodá-los em um regressão linear múltipla:

$$
\begin{equation}
\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X_1 + \hat{\beta_2} X_2 + \ldots + \hat{\beta_q} X_q + \epsilon
(\#eq:reg-linear-multiple)
\end{equation}
$$

Em vez de uma linha, tem-se um modelo linear – a relação entre cada coeficiente e sua variável (feature) é linear. Essa equação é conhecida como regressão linear múltipla ou [*multiple linear regression*]{.unerline} \@ref(eq:reg-linear-multiple). Todos os outros conceitos da regressão linear simples, como o ajuste por mínimos quadrados e a definição de valores ajustados e resíduos, estendem-se à configuração de regressão linear múltipla.

\
A [**regressão logística**]{.underline} é análoga à regressão linear múltipla \@ref(eq:reg-linear-multiple), exceto que o resultado é [binário]{.underline}. Várias transformações são empregadas para converter o problema em algo no qual um modelo linear possa ser ajustado. A regressão logística é uma abordagem de modelo estruturado, em vez de uma abordagem centrada em dados. Devido à sua velocidade de processamento com menor custo computacional e sua rapidez na classificação de novos dados, é um método bastante adotado.

Os principais ingredientes para a regressão logística são a função de resposta logística ou *logistic response function* \@ref(eq:logistic-response) e a função log-odds ou logit \@ref(eq:logit), no qual mapeia-se uma probabilidade (entre 0 e 1) para uma escala mais ampla, adequada para modelagem linear.

O primeiro passo é pensar na variável de resultado não como um rótulo binário, mas como a probabilidade $p$ de que o rótulo seja “1”. Ingenuamente, podemos cair na tentação de modelar $p$ como uma função linear das variáveis explicativas:

$$
p = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q
$$

No entanto, ajustar esta função não garante que $p$ resulte em um número entre 0 e 1, como tem que acontecer com uma probabilidade. Então, é necessário modelar $p$ aplicando uma *logistic response function* \@ref(eq:logistic-response) às variáveis explicativas:

$$
\begin{equation}
p = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q)}}
(\#eq:logistic-response)
\end{equation}
$$

Essa transformação garante que $p$ permaneça entre 0 e 1.

Para tirar a expressão exponencial do denominador, pode-se expressar essa equação em termos de "chances" ou [*odds*]{.underline} em vez de probabilidade.

A chance, conceito familiar aos apostadores do mundo todo, é a razão entre “sucessos” (1) e “fracassos” (0). Na linguagem de probabilidade, "chances" são a probabilidade de um evento ocorrer dividida pela probabilidade de o evento não ocorrer. Por exemplo, se a probabilidade de um cavalo ganhar for $0,5$, a probabilidade de “não ganhar” é $(1 – 0,5) = 0,5$ e as chances são de 1 pra 1, então:

$$
Odds(Y=1) = \frac{p}{1-p}
$$

É possível obter a probabilidade a partir das chances usando o inverso da função de chances:

$$
p = \frac{Odds(Y=1)}{1 + Odds(Y=1)}
$$

Combinando isso com a *logistic response function* \@ref(eq:logistic-response) vista anteriormente, tem-se que:

$$
Odds(Y=1) = e^{\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q}
$$

Finalmente, tirando o logaritmo natural de ambos os lados, obtém-se uma equação que é uma função linear das variáveis explicativas:

$$
\begin{equation}
log(Odds(Y=1)) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q
(\#eq:logit)
\end{equation}
$$

A função *log-odds*, também conhecida como função logit \@ref(eq:logit), mapeia a probabilidade $p$ de $(0,1)$ para qualquer valor $(-\infty, +\infty)$. Assim o círculo de transformação se fecha, aplicando um modelo linear para prever uma probabilidade, que por sua vez pode ser mapeado para um rótulo de classe aplicando-se uma regra de corte – qualquer observação com uma probabilidade maior que o ponto de corte é classificado como 1.

```{r logit, echo=FALSE, fig.cap="*Gráfico de função logit que coloca uma probabilidade em uma escala aplicável a um modelo linear.*", fig.width=5, fig.asp=.7}
# Plot logit(p) x p
ggplot(data=tibble(x=seq(0.01, 0.99, by=0.01), 
                   y=log(seq(0.01, 0.99, by=0.01)/(1-seq(0.01, 0.99, by=0.01)))),
       aes(x=x, y=y)) +
  geom_line(color="blue") +
  labs(x="p", y="logit(p)")
```

\

A resposta na função de regressão logística é o log das probabilidades de um resultado binário de 1. O resultado desejado, porém, é apenas o resultado binário e não o log das probabilidades, portanto são necessários métodos estatísticos adicionais para ajustar o resultado da equação a um limite de corte.

\

# XXX Modelos de Classificação

**Com a base escolhida:**

## Etapas de modelagem

**Descreva as etapas necessárias para criar um modelo de classificação eficiente.**

[Kuhn e Silge (2023)](#references) propõem uma descrição do processo genérico de modelagem preditiva que pode ser dividido nos seguintes passos:

1.  Definir o objetivo
2.  Analisar os dados (Exploratory Data Analysis - EDA)
3.  Transformar os dados para modelagem (*Feature Engineering*)
4.  Ajustar e selecionar modelo
5.  Testar projeções no modelo selecionado
6.  Documentar e comunicar conclusões

\
**(1) Definir o objetivo**

Esta etapa não está formalmente definida no processo descrito por [Kuhn e Silge (2023)](#references), porém considero que seja extremamente importante destacar que um processo de modelagem se inicie por uma definição do seu objetivo específico. Sem isso, o cientista de dados arrisca se perder nas etapas seguintes – especialmente na análise exploratória dos dados (EDA).

É especialmente importante definir se o objetivo da modelagem é fazer previsões ([modelagem preditiva]{.underline}) ou explicar relações causais entre as variáveis ([modelagem explicativa]{.underline}). [Shmueli (2010)](#references) descreve as diferenças entre modelos preditivos e modelos explicativos e suas implicações para o processo de modelagem no artigo "*To Explain or to Predict?*". A depender do objetivo da modelagem, diferentes escolhas podem ser feitas, por exemplo, sobre a seleção das variáveis dependentes ou sobre a avaliação da performance do modelo. Em grandes linhas, as etapas do processo de modelagem podem ser aplicadas tanto à modelagem preditiva quanto explicativa, porém a descrição de cada etapa a seguir é voltada para modelagem preditiva, dado o contexto desta disciplina de Modelos Preditivos.

Acredito que possa haver iteração entre a definição do objetivo e o passo seguinte de análise exploratória dos dados (EDA). É possível iniciar-se uma modelagem a partir de um objetivo e alterar ou ajustar o objetivo com base nas descobertas extraídas da análise exploratória de dados. Porém, é importante que os passos seguintes – Feature Engineering, Ajuste e seleção do modelo e Teste das projeções – sejam orientadas pelo objetivo específico predeterminado.

A definição do objetivo deve especificar qual pergunta ou perguntas serão respondidas pelo processo de modelagem.

No caso concreto deste projeto, por exemplo, o objetivo é avaliar a propensão ou risco de rotatividade dos clientes de uma empresa de telecomunicações. O projeto fará uma modelagem para classificação dos clientes entre contratos cancelados ou não cancelados, gerando um modelo final que ajudará a empresa a identificar clientes altamente propensos ao cancelamento de forma que sua área comercial possa atuar especificamente sobre estes clientes. Adicionalmente, gostaríamos de poder reportar a importância relativa das variáveis explicativas do modelo final para identificar os fatores mais influenciadores do risco de cancelamento do cliente.

\
**(2) Analisar os dados (EDA)**

Assumindo-se que o analista esteja partindo de um conjunto pré-selecionado de dados (i.e., desconsiderando-se etapas de desenho de coleta de dados primários ou experimentos), há um processo iterativo entre avaliação e visualização de dados onde diferentes descobertas levam a mais perguntas e talvez buscas paralelas de dados adicionais para obter maior compreensão sobre o problema.

É comum que esta etapa tome mais tempo do que o restante do processo de modelagem. [Wickham, e Grolemund (2023)](#0) contém uma excelente ilustração do processo geral de análise de dados, reproduzida na figura abaixo. A leitura (*Import*) e a limpeza/preparação (*Tidy*) dos dados são mostradas como as etapas iniciais. As etapas analíticas de transformação, visualização e modelagem descritiva geralmente requerem múltiplas iterações antes que se possa, finalmente apresentar os resultados (*Communicate*).

![Processo típico de análise dos dados (Wickham et al. 2023)](.imgs/DataAnalysisProcess.png){alt="Processo típico de análise dos dados (Wickham et al. 2023)" width="400"}\

Deve-se sempre investigar os dados para garantir que eles sejam precisos, adequados e aplicáveis ao objetivo específico da modelagem. A análise exploratória de dados (EDA) pode trazer à tona como as diferentes variáveis estão relacionadas entre si, suas distribuições, intervalos típicos e outros atributos.

Uma boa pergunta a ser feita nesta fase é: "Como obtive esses dados?" Esta pergunta pode ajudar a entender como a amostra foi coletada ou filtrada e se isso foi feito de forma adequada. Existem lacunas nos dados? Essas lacunas são significativas? Qual é a maneira adequada de lidar com essas lacunas? Pode-se excluir as observações com lacunas? Deve-se fazer uma imputação dos dados faltantes? Por técnicas simplistas (e.g. imputação da média, mediana) ou utilizando alguma técnica de modelagem exclusivamente para a imputação das lacunas (e.g. interpolação linear).

Outra boa pergunta a ser respondida nessa etapa é se os dados são relevantes para o objetivo proposto. Qual é a variável de saída/*target*? Quais devem ser suas variáveis explicativas? Deve-se manter todas as variáveis ou selecionar apenas as variáveis com maior potencial de influência nas novas projeções de dados? Há correlações entre as variáveis explicativas? Como isso afeta a modelagem? Essas são algumas perguntas exploratórias que podem começar a ser respondidas durante a etapa de EDA.

Nesta etapa é possível, inclusive, aplicar técnicas de modelagem especificamente para esclarecer a relação entre as variáveis e descobrir a melhor maneira de representar essa relação dentro do modelo preditivo, como por exemplo *Locally Estimated Scatterplot Smoothing* – LOESS.

A etapa de análise de dados, deve estabelecer qual técnica ou técnicas de modelagem serão aplicadas (Regressão Logística, Decision Tree, Random Forest, Redes Neurais, etc. ou mesmo um "*ensemble*" de diferentes técnicas?) para atingir o objetivo determinado.

E finalmente, deve-se definir expectativas claras de como o desempenho (e o sucesso) da modelagem serão avaliados. Pelo menos uma métrica de desempenho deve ser identificada com objetivos realistas do que pode ser alcançado. Os benefícios e desvantagens relativos dessas métricas devem ser ponderados. Também é importante que a métrica seja pertinente – seu alinhamento com os objetivos da análise de dados é crítico.

Nessa etapa também deve-se definir a estratégia de particionamento dos dados a ser adotada para a validação do modelo. Os dados serão separados em treino e teste? Se sim, é recomendável que as análises exploratórias sejam feitas sobre o conjunto de dados de treino, isolando os dados de teste desde o início da modelagem. Será aplicada alguma metodologia de reamostragem? Como mencionado na pergunta [4.1 Validação cruzada](#validacao-cruzada), pode-se escolher algum tipo de validação cruzada, além de outras metodologias desenhadas para mitigar problemas específicos de tamanho ou distribuição dos dados da amostra de treino, como *bootstrapping*.

\
**(3) Feature Engineering**

Os insights de EDA e as decisões tomadas naquela etapa auxiliarão na criação de termos ou componentes de modelo específicos para a modelagem dos dados observados. A transformação dos dados pode incluir metodologias complexas (por exemplo, *Principal Component Analysis - PCA*) ou recursos mais simples (combinando uma medida de altura e outra de largura em uma nova variável da área).

\
**(4) Ajustar e selecionar modelo(s)**

Nessa etapa os modelos são gerados e seu desempenho é comparado. Alguns modelos exigem ajuste de parâmetros em que alguns parâmetros estruturais devem ser especificados ou otimizados.

\
**(5) Testar projeções**

Durante esta fase, as métricas de desempenho do modelo são avaliadas examinando o resíduo ou erro de projeção no conjunto de dados separado para teste. Podem ser feitas outras análises complementares para entender o quão bem o(s) modelo(s) funciona(m).

\
O processo de modelagem é iterativo. Após uma execução inicial dessa sequência de passos, mais entendimento é obtido sobre quais modelos são superiores, bem como quais sub-amostras de dados não estão sendo estimadas efetivamente. Isso leva a EDA adicional e feature engineering, outra rodada de modelagem e assim por diante.

\
**(6) Documentar e comunicar conclusões**

Quando os objetivos originais da modelagem são alcançadas, normalmente as últimas etapas são finalizar, documentar e comunicar o modelo.


## Modelagem

\

Escolhe as métricas de classificação e de probabilidade para avaliar a performance de **todos** os modelos.

```{r}
performance_metrics <- 
  metric_set(accuracy, 
             roc_auc, sensitivity, specificity,
             f_meas, precision, recall, # <== f_meas = F1-score
             brier_class)
```

\

### Regressão logística

**Treine um modelo de regressão logística para realizar a classificação.**

\

[Etapa 3] Transforma os dados para modelagem (*Feature Engineering*)

```{r}
rec_upsample_dummy <- 
  recipe(Churn ~ ., data=df1_train) |> 
  update_role(customerID, new_role="ID") |> # Desconsidera a variável ID na modelagem
  step_dummy(all_nominal_predictors()) |>   # Transforma variáveis categóricas em dummies
  themis::step_upsample(Churn)              # Upsampling da classe minoritária do Churn
```

\

Checa aplicação da receita no dataset de treino.

```{r}
rec_trained <- 
  prep(rec_upsample_dummy, training=df1_train, retain=TRUE) |> 
  juice()

str(rec_trained)
```

\

Checa balanceamento do Churn.

```{r}
count(rec_trained, Churn)
```


\

[Etapa 4] Define especificações/ hiperparâmetros aplicáveis e ajusta (treina) o modelo.

```{r}
lgreg_spec <- 
  logistic_reg() |>
  set_engine("glm") |>
  set_mode("classification")

set.seed(888)
lgreg_fit <- 
  workflow() |>
  add_model(lgreg_spec) |> 
  add_recipe(rec_upsample_dummy) |>
  fit(data=df1_train)

lgreg_fit
```


\

Extrai coeficientes da regressão:

```{r}
lgreg_coefs <- 
  tidy(lgreg_fit) |> 
  mutate(lg_significance = if_else(p.value < 0.05, 
                                   "Significativo (p.value < 0,05)", 
                                   "Não significativo (p.value > 0,05)"))
```



```{r echo=FALSE}
lgreg_coefs |> 
  mutate(estimate_abs = abs(estimate),
         pct_std.error = std.error/abs(estimate)*100) |>
  arrange(desc(lg_significance), desc(abs(estimate))) |> 
  group_by(lg_significance) |> 
  gt(rowname_col="stub", locale="pt") |> sub_missing() |>
  gtExtras::gt_plt_bar(estimate_abs, width=20) |> 
  gtExtras::gt_plt_bar_pct(pct_std.error,scaled=T) |>
  fmt_number(estimate:statistic, decimals=2) |> 
  fmt_scientific(p.value) |>
  tab_options(
    heading.align="left", heading.title.font.size=pct(100), heading.subtitle.font.size=pct(90),
    column_labels.font.weight="bold", column_labels.font.size=pct(80),
    column_labels.text_transform="uppercase", column_labels.background.color="gray95",
    data_row.padding=px(2), row_group.padding=px(2), row_group.font.weight="bold",
    table.font.size=pct(80), source_notes.font.size = pct(70),
  ) |> 
  tab_header(title = md("**Estimativa dos coeficientes da regressão logística**"))
```


\

[Etapa 5] Testa projeções do modelo


Gera previsões sobre a base de teste e calcula medidas de performance do modelo.

```{r}
# Gera um dataset de teste com previsões
lgreg_test <- augment(lgreg_fit, new_data=df1_test)

# Gera um dataset da matriz de confusão
df3_conf_matrix <- 
  conf_mat(lgreg_test, truth=Churn, estimate=.pred_class) |> 
  tidy() |> 
  tidyConfMat() |> 
  mutate(model="LogReg0")

# Grava a curva ROC do modelo
lgreg_roc_curve <- 
  lgreg_test |> 
  roc_curve(truth=Churn, .pred_Churned)
```


\

```{r echo=FALSE, fig.asp=1, fig.width=2}
plotConfMat(df3_conf_matrix)
```

\

```{r echo=FALSE, fig.width=3, fig.asp=1}
autoplot(lgreg_roc_curve, size=1.5) +
  scale_x_continuous(expand=expansion(mult=c(0,0))) +
  scale_y_continuous(expand=expansion(mult=c(0,0))) +
  theme_light(base_size=9) +
  theme(
    plot.title = element_text(size=10, colour="gray30", face="bold"),
    plot.subtitle = element_text(face='italic', colour="gray50", size=9),
    axis.title = element_text(size=7)
  ) +
  labs(title="ROC Curve", 
       subtitle="Regressão logística",
       x="False Positive Rate (specificity)", y="True Positive Rate (sensitivity)")
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo.?**

Junta resultados de performance em um dataset para comparação entre modelos.

```{r}
df4_performance <- 
  lgreg_test |> 
  performance_metrics(truth=Churn, estimate=.pred_class, .pred_Churned) |> 
  mutate(.estimate = round(.estimate, 4),
         model="LogReg0")
```


```{r}
df4_performance |> 
  filter(.metric %in% c("accuracy", "precision", "recall", "f_meas", "roc_auc"))
```

```{r include=FALSE}
rm(rec_trained); gc()
```


\

### Árvore de Decisão

**Treine um modelo de árvore de decisão para realizar a classificação.**

\

[Etapa 3] Transforma os dados para modelagem (*Feature Engineering*)

```{r}
rec_upsample <- 
  recipe(Churn ~ ., data=df1_train) |> 
  update_role(customerID, new_role="ID") |>  # Desconsidera a variável ID na modelagem
  themis::step_upsample(Churn)  
```


\

Checa aplicação da receita no dataset de treino.

```{r}
rec_trained <- 
  prep(rec_upsample, training=df1_train, retain=TRUE) |> 
  juice()

str(rec_trained)
```


\

Checa balanceamento do Churn.


```{r}
count(rec_trained, Churn)
```



\

[Etapa 4] Define especificações/ hiperparâmetros aplicáveis e ajusta (treina) o modelo.

```{r}
tree_spec <- 
  decision_tree(tree_depth=5) |>
  set_engine("rpart") |>
  set_mode("classification")

tree_fit <- 
  workflow() |>
  add_model(tree_spec) |> 
  add_recipe(rec_upsample) |>
  fit(data=df1_train)

tree_fit
```


\

Visualiza a árvore de decisão gerada pelo modelo.

```{r dectree, fig.cap="Árvore de decisão gerada pelo modelo de classificação.", out.width=500, fig.align="center"}
extract_fit_engine(tree_fit) |> 
  rpart.plot::rpart.plot(yes.text="SIM", no.text="NÃO", roundint=FALSE)
```

\

[Etapa 5] Testa projeções do modelo


Gera previsões sobre a base de teste e calcula medidas de performance do modelo.

```{r}
# Gera um dataset de teste com previsões:
tree_test <- augment(tree_fit, new_data=df1_test)

# Gera um dataset da matriz de confusão de cada modelo
df3_conf_matrix <- 
  bind_rows(
    df3_conf_matrix,
    conf_mat(tree_test, truth=Churn, estimate=.pred_class) |> 
      tidy() |> 
      tidyConfMat() |> 
      mutate(model="DecTree0")
  )
```


\

```{r fig.asp=1, fig.width=2}
df3_conf_matrix |> 
  filter(model=="DecTree0") |> 
  plotConfMat() 
```

\

```{r fig.width=3, fig.asp=1}
tree_roc_curve <- 
  tree_test |> 
  roc_curve(truth=Churn, .pred_Churned)

autoplot(tree_roc_curve, size=1.5) +
  scale_x_continuous(expand=expansion(mult=c(0,0))) +
  scale_y_continuous(expand=expansion(mult=c(0,0))) +
  theme_light(base_size=9) +
  theme(
    plot.title = element_text(size=10, colour="gray30", face="bold"),
    plot.subtitle = element_text(face='italic', colour="gray50", size=9),
    axis.title = element_text(size=7)
  ) +
  labs(title="ROC Curve", 
       subtitle="Decision Tree",
       x="False Positive Rate (specificity)", y="True Positive Rate (sensitivity)")
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**

Junta resultados de performance em um dataset para comparação entre modelos.

```{r}
df4_performance <- 
  bind_rows(
    df4_performance,
    tree_test |> 
      performance_metrics(truth=Churn, estimate=.pred_class, .pred_Churned) |> 
      mutate(.estimate = round(.estimate, 4),
             model="DecTree0")
  )
```


```{r}
df4_performance |> 
  filter(model=="DecTree0") |> 
  filter(.metric %in% c("accuracy", "precision", "recall", "f_meas", "roc_auc"))
```


```{r include=FALSE}
rm(rec_trained); gc()
```


\

### Random Forest

**Treine um modelo de random forest para realizar a classificação.**

\

Nota: reutiliza a mesma receita de *feature engineering* da árvore de decisão.

\

[Etapa 4] Define especificações/ hiperparâmetros aplicáveis e ajusta (treina) o modelo.


```{r}
rf_spec <- 
  rand_forest(
    mtry  = 2,  # nr de preditores que serão escolhidos aleatoriamente, default = sqrt(ncol(x))
    min_n = 10, # target nr de obs no nó para split, default = 10 ou 5 para classificação
    trees = 500
  ) |>
  set_engine("ranger", num.threads=parallel::detectCores(), importance="impurity_corrected") |>
  set_mode("classification")

set.seed(2021)
rf_fit <- 
  workflow() |>
  add_recipe(rec_upsample) |> # <== mesma receita da árvore de decisão
  add_model(rf_spec) |>
  fit(df1_train)

rf_fit
```

\

[Etapa 5] Testa projeções do modelo


Gera previsões sobre a base de teste e calcula medidas de performance do modelo.

```{r}
rf_test <- augment(rf_fit, new_data=df1_test)
```


\

Antes de checar performance, vamos verificar a importância das variáveis.


```{r rf_vars, echo=FALSE, fig.cap="Importância das variáveis do modelo de Random Forest.", fig.width=6, fig.asp=.6}
rf_res_features <- ranger::importance(extract_fit_engine(rf_fit)) |> tidy() |> 
  arrange(desc(x))

rf_res_features |> 
  mutate(names = fct_reorder(names, x)) |>
  ggplot(aes(x=x, y=names)) +
  geom_col(fill="cadetblue") +
  scale_x_continuous(expand=expansion(mult=c(0,0.1))) +
  theme(panel.grid.major.y=element_blank()) +
  labs(title="Importância relativa das variáveis - Random Forest", 
       subtitle="Baseado no índice Gini ajustado",
       x="Importance", y=NULL)
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**



```{r}
df3_conf_matrix <- 
  bind_rows(
    df3_conf_matrix,
    conf_mat(rf_test, truth=Churn, estimate=.pred_class) |> 
      tidy() |> tidyConfMat() |> 
      mutate(model="RndFor0")
  )
```


```{r echo=FALSE, fig.asp=1, fig.width=2}
plotConfMat(df3_conf_matrix |> filter(model=="RndFor0"))
```

\

```{r echo=FALSE, fig.width=3, fig.asp=1}
rf_roc_curve <- rf_test |> 
  roc_curve(truth=Churn, .pred_Churned)

suppressMessages(
  print(
    autoplot(rf_roc_curve) +
      coord_cartesian(xlim = c(0,1), ylim=c(0,1.01), expand = FALSE) +
      theme_light(base_size=9) +
      labs(title="ROC curve of Random Forest model", 
           x="False Positive Rate (specificity)", y="True Positive Rate (sensitivity)")
  )
)
```
\

```{r}
df4_performance <- 
   bind_rows(
     df4_performance,
     rf_test |> 
       performance_metrics(truth=Churn, estimate=.pred_class, .pred_Churned) |> 
       mutate(.estimate = round(.estimate, 4),
              model="RndFor0")
   )
```


```{r}
df4_performance |> 
  filter(model=="RndFor0", .metric %in% c("accuracy", "precision", "recall", "f_meas"))
```

\

### Redes Neurais

**Treine um modelo de rede neural rasa para realizar a classificação.**

\

[Etapa 3] Transforma os dados para modelagem (*Feature Engineering*)

```{r}
rec_upsample_dummy_normalize <- 
  rec_upsample_dummy |> 
  step_center(all_predictors()) |> # Centraliza as variáveis para média = 0
  step_scale(all_predictors())    # Escala as variáveis para desvio padrão = 1
```


\

Checa aplicação da receita no dataset de treino.

```{r}
rec_trained <- 
  prep(rec_upsample_dummy_normalize, training=df1_train, retain=TRUE) |> 
  juice()

str(rec_trained)
```


\

Checa balanceamento do Churn.


```{r}
count(rec_trained, Churn)
```

\

[Etapa 4] Define especificações/ hiperparâmetros aplicáveis e ajusta (treina) o modelo.


```{r}
nn_spec <-
  mlp(hidden_units=6, epochs=150, penalty=0) |>
  set_engine("nnet") |>
  set_mode("classification")

set.seed(2021)
nn_fit <-
  workflow() |>
  add_recipe(rec_upsample_dummy_normalize) |>
  add_model(nn_spec) |>
  fit(df1_train)

nn_fit
```

\

[Etapa 5] Testa projeções do modelo


Gera previsões sobre a base de teste e calcula medidas de performance do modelo.

```{r}
nn_test <- augment(nn_fit, new_data=df1_test)
```


\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**


```{r}
df3_conf_matrix <- 
  bind_rows(
    df3_conf_matrix,
    conf_mat(nn_test, truth=Churn, estimate=.pred_class) |> 
      tidy() |> tidyConfMat() |> 
      mutate(model="NNet0")
  )
```


```{r echo=FALSE, fig.asp=1, fig.width=2}
plotConfMat(df3_conf_matrix |> filter(model=="NNet0"))
```

\

```{r echo=FALSE, fig.width=3, fig.asp=1}
nn_roc_curve <- nn_test |> 
  roc_curve(truth=Churn, .pred_Churned)

suppressMessages(
  print(
    autoplot(nn_roc_curve) +
      coord_cartesian(xlim = c(0,1), ylim=c(0,1.01), expand = FALSE) +
      theme_light(base_size=9) +
      labs(title="ROC curve of Neural Network", 
           x="False Positive Rate (specificity)", y="True Positive Rate (sensitivity)")
  )
)
```
\

```{r}
df4_performance <- 
   bind_rows(
     df4_performance,
     nn_test |> 
       performance_metrics(truth=Churn, estimate=.pred_class, .pred_Churned) |> 
       mutate(.estimate = round(.estimate, 4),
              model="NNet0")
   )
```


```{r}
df4_performance |> 
  filter(model=="NNet0", .metric %in% c("accuracy", "precision", "recall", "f_meas"))
```


\


# Melhor modelo

**Em relação à questão anterior, qual o modelo deveria ser escolhido para uma eventual operação.**

```{r echo=FALSE, fig.width=6, fig.asp=.3}
df3_conf_matrix |> 
  mutate(model = factor(model, levels=c("LogReg0", "DecTree0", "RndFor0", "NNet0"))) |> 
  plotConfMat()
```

\

```{r}
df4_performance |> 
  mutate(
    model = factor(model, levels=c("LogReg0", "DecTree0", "RndFor0", "NNet0")),
    .metric = factor(.metric, levels=c("f_meas", "precision", "recall", 
                                       "roc_auc", "sensitivity", "specificity",
                                       "accuracy", "brier_class"))
  ) |>
  ggplot(aes(x=model, y=.estimate, group=.metric)) +
  geom_line(aes(color=.metric), linewidth=.7) + geom_point(aes(color=.metric)) +
  geom_text(aes(label=scales::number(.estimate, accuracy=.01)), vjust=-1, size=3) +
  facet_wrap(~.metric, scales="free_y", ncol=3) +
  scale_y_continuous(expand=expansion(mult=c(0.2,0.25))) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position="none",
        panel.grid.major=element_blank()) +
  labs(title="Comparison of model metrics", 
       x=NULL, y=NULL)
```

\

```{r fig.width=5, fig.asp=1}
pltROC <- function(workflow, model_name) {
  autoplot(workflow) +
    scale_x_continuous(expand=expansion(mult=c(0,0))) +
    scale_y_continuous(expand=expansion(mult=c(0,0))) +
    labs(
      title=glue::glue(
        "{model_name} (AUC: {filter(df4_performance, .metric=='roc_auc', model=={model_name})$.estimate})"
      ), 
      x="False Positive Rate (specificity)", y="True Positive Rate (sensitivity)"
    )
}


p1 <- pltROC(lgreg_roc_curve, "LogReg0")
p2 <- pltROC(tree_roc_curve, "DecTree0")
p3 <- pltROC(rf_roc_curve, "RndFor0")
p4 <- pltROC(nn_roc_curve, "NNet0")


p1 + p2 + p3 + p4 &
  theme_light(base_size=8) &
  theme(axis.title = element_text(size=7))
```




\

# Deep Learning

**Descreva em suas palavras o que é Deep Learning.**

Deep Learning é uma categoria de Machine Learning que usa métodos de Redes Neurais para processar dados de treino por meio de camadas de funções não lineares ponderadas (neurônios). Um algoritmo de aprendizado atualiza sucessivamente os parâmetros da rede neural para melhorar a qualidade da estimativa.

Se uma Rede Neural tem muitos neurônios (frequentemente milhões ou mais) e se esses neurônios são organizados em muitas camadas, geralmente com funcionalidades variadas, o algoritmo é chamado de algoritmo de Deep Learning.

Processamento de Linguagem Natural (NLP), reconhecimento avançado de imagem e complementação de código de programação são exemplos de aplicações que usam Deep Learning.

\

# FIM

*Antes de fazer sua entrega, reúna todos os arquivos relativos ao seu Projeto de Disciplina em um único arquivo no formato .zip e poste no Moodle. Utilize o seu nome para nomear o arquivo, identificando também a disciplina, como no exemplo: “nomedoaluno_nomedadisciplina_pd.zip”.*

\

# Referências Bibliográficas {#references}

\
Bruce, P., Bruce, A. e Gedeck, P. (2020). *"Practical Statistics for Data Scientists".* O’reilly Media, Inc. ISBN-13: 978-1492072911.

\
NOT QUOTED: Geisser, S. (1993). *"Predictive Inference: An Introduction".* Chapman and Hall, Londres. DOI: 10.1201/9780203742310. [[online](https://doi.org/10.1201/9780203742310)]

\
Kuhn, M. e Silge, J. (2023). *"Tidy Modeling with R: A Framework for Modeling in the Tidyverse".* O’reilly Media, Inc. ISBN-13: 978-1492096450 [[online](https://www.tmwr.org/)]

\
Lange, C. (2024). *"Practical Machine Learning with R, 1st Edition".* Chapman & Hall. ISBN-13: 978-1032434056. [[online](https://www.routledge.com/Practical-Machine-Learning-with-R-Tutorials-and-Case-Studies/Lange/p/book/9781032434056)]

\
Shmueli, G. (2010). *"To Explain or to Predict?"* Journal of Statistical Science, Institute of Mathematical Statistics [online] v. 25, n. 3, p. 289–310. DOI: 10.1214/10-STS330. [[online](https://projecteuclid.org/euclid.ss/1294167961)]

\
Wickham, H., Çetinkaya-Rundel, M. e Grolemund, G. (2023). *"R for Data Science, 2nd Edition".* O'Reilly Media, Inc. ISBN-13: 978-1492097365. [[online](https://r4ds.hadley.nz/)]

\

------------------------------------------------------------------------
