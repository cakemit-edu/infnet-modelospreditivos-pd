---
title:  Projeto da Disciplina de Modelos Preditivos
author: Claudia Tanaka (claudia.tanaka@al.infnet.edu.br)
date:   "Atualizado em `r format(Sys.time(), '%d/%m/%Y')`"

output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( message=FALSE, warning=FALSE )
options(scipen=999) # "Desliga" notação científica. 

# PACOTES 
library(tidyverse)

# PRETTY DOC
library(gt)
library(patchwork)

theme_set(theme_light())
theme_update(
  panel.grid.minor = element_blank(),
  plot.title = element_text(size = 12, colour = "gray30", face = "bold"),
  plot.subtitle = element_text(face = 'italic', colour = "gray50", size = 10),
  plot.caption = element_text(colour = "gray50", hjust=0, size = 8),
  legend.title = element_blank(),
)
```

\

Nessa disciplina, aprofundamos nossos conhecimentos em modelos preditivos, tarefa que é extremamente importante para o dia-a-dia de um cientista de dados. Agora iremos validar nosso conhecimento.

Para a realização desse trabalho, será necessário utilizar a plataforma Knime e seus componentes para uso de algoritmos de Machine Learning.

Escolha uma base de dados para realizar esse projeto, onde você utilizará algoritmos de classificação. Essa base necessita ter 4 (ou mais) variáveis de interesse e 2 (apenas 2!) classes (rótulos). Caso você tenha dificuldade para escolher uma base, o(a) professor(a) da disciplina irá designar uma para você.

\

# Knime

**No relatório final, anexe um printscreen evidenciando que o Knime está funcionando com os componentes**

![Printscreen do Knime instalado na minha máquina](.imgs/knime1.png)

\

# Base escolhida

**Explique a motivação de uso da base escolhida.**

O objetivo deste projeto é prever a rotatividade (churn) de clientes em uma empresa de telecomunicações. Exploraremos modelos analíticos preditivos para avaliar a propensão ou risco de rotatividade dos clientes. Esses modelos podem gerar uma lista de clientes mais vulneráveis à rotatividade, para que as empresas possam trabalhar no sentido de retê-los.

Este projeto é baseado em um [conjunto de dados da IBM no Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn).

```{r}
df0 <- read.csv("_datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv") |> 
  as_tibble() |> 
  mutate(SeniorCitizen = if_else(SeniorCitizen==0, "No", "Yes")) |> 
  mutate(across(where(is.character), as.factor)) |> 
  # Ordena para que a classificação de referência seja "Yes"
  mutate(Churn = fct_rev(Churn))
```

Só há lacunas nos dados de TotalCharges

```{r}
colSums(is.na(df0)) |> as.data.frame() |> rownames_to_column() |> rename(coluna=1,nulos=2) |> 
  filter(nulos>0) |> arrange(desc(nulos))
```

\

# Variáveis

**Descreva as variáveis presentes na base. Quais são as variáveis? Quais são os tipos de variáveis (discreta, categórica, contínua)? Quais são as médias e desvios padrões?**

Cada linha representa um cliente, cada coluna contém os seguintes atributos do cliente.

Este conjunto de dados inclui as seguintes 20 [*features*]{.underline}:

-   [dados demográficos]{.underline}: Gender (gênero), SeniorCitizen (flag de idoso), Partner (se tem parceiro), Dependents (se tem dependentes)

-   [serviços assinados]{.underline}: PhoneService, MultipleLine, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies

-   [informações da conta do cliente]{.underline}: CustomerID, Contract, PaperlessBilling (recebe a fatura online), PaymentMethod (método de pagamento), MonthlyCharges (mensalidade), TotalCharges (total incluindo mensalidade), Tenure (há quantos meses é cliente)

O alvo é `Churn`, que é um flag binário sim ou não.

```{r}
glimpse(df0)
```

Todas as variáveis são categóricas, exceto as duas variáveis numéricas contínuas: (1) mensalidade (`MonthlyCharges`); e (2) valor total incluindo mensalidade (`TotalCharges`) e a variável numérica discreta `Tenure` (há quantos meses é cliente)

Estatísticas descritivas das variáveis numéricas:

```{r}
summary(df0 |> select(is.numeric))
```

\

# XXX Seleção de modelos e EDA

**Em relação à base escolhida:**

**(1) Você irá comparar alguns modelos para prever as classes. Descreva como a validação cruzada pode ser usada para comparar modelos de maneira justa. Descreva o procedimento e como uma métrica final é calculada.**

XXXXXXXX

\

**(2) A base se encontra com as classes balanceadas? Cite uma maneira resolver no caso das classes estarem desbalanceadas.**

Neste conjunto de dados de mais de 7.000 clientes, 26% deles saíram no último mês. Isto é fundamental para o negócio de telecomunicações porque muitas vezes é mais caro adquirir novos clientes do que manter os existentes.

```{r}

```

\

# Regressão Linear x Logística

**Qual a diferença entre uma regressão linear e a regressão logística?**

Em resumo, a regressão linear é um método de modelagem de dados utilizado para prever uma variável contínua a partir de uma relação linear estimada com uma ou mais variáveis. A regressão logística é um caso específico de um modelo linear generalizado (GLM - generalized linear model) desenvolvido para estender a aplicação da regressão linear a um contexto em que se deseje prever uma variável categórica binária (sim/não, 0/1, evento/não evento).

Assim, apesar de ambos serem modelos lineares, a principal diferença entre os dois métodos é que a regressão linear é utilizada para prever variáveis numéricas contínuas, enquanto a regressão logística é utilizada para prever variáveis categóricas binárias.

\
Mais especificamente, com base nos capítulos sobre Regressão Linear simples, Regressão Linear multivariável e Regressão Logística do livro *Practical Statistics for Data Scientists* de [Bruce et al (2020)](#references):

A [**regressão linear simples**]{.underline} fornece um modelo da relação entre a magnitude de uma variável e a de uma segunda – por exemplo, à medida que X aumenta, Y também aumenta. Ou à medida que X aumenta, Y diminui. Coeficiente de correlação é outra forma de medir como duas variáveis estão relacionadas. A diferença é que enquanto a correlação mede a força de uma associação entre duas variáveis, a regressão quantifica a natureza da relação.

A regressão linear simples estima quanto Y mudará quando Y mudar em um determinado valor. Com o coeficiente de correlação, as variáveis X e Y são intercambiáveis. Com a regressão, tentamos prever a variável Y a partir de X usando uma relação linear (ou seja, uma linha):

$$
Y = \beta_0 + \beta_1 X
$$

O símbolo $\beta_0$ é a constante que determina a intercecção com o eixo Y se X fosse igual a zero, e o símbolo $\beta_1$ é o coeficiente da inclinação de X. A variável Y é conhecida como [*target*]{.underline} ou variável dependente, pois depende de X. A variável X é conhecida como preditor, [*feature*]{.underline} ou variável independente.

Considerando o gráfico de dispersão na Figura \@ref(fig:5-1) que mostra a largura da pétala de um tipo de flor (`Petal.Width`) versus o comprimento da sua pétala, pode-se visualizar como a largura está relacionada ao comprimento das pétalas. Parece que quanto maior o comprimento, maior a largura.

```{r 5-1, echo=FALSE, fig.cap="*Gráfico de dispersão Sepal.Length x Sepal.Width*", fig.width=5, fig.asp=.7}
iris |> 
  filter(Species == "versicolor") |>
  ggplot(aes(x=Petal.Length, y=Petal.Width)) +
  geom_point() +
  labs(title = "Gráfico de dispersão Sepal.Length x Sepal.Width",
       subtitle = "Iris dataset")
```

\

A regressão linear simples tenta encontrar a “melhor” linha reta ou a linha reta mais ajustada para prever a variável target Y=`Petal.Width` em função da feature X=`Petal.Length`:

$$
Petal.Width = \beta_0 + \beta_1 Petal.Length
$$

A linha de regressão deste modelo é exibida na Figura \@ref(fig:5-2).

```{r 5-2, echo=FALSE, fig.cap="*Gráfico de dispersão Sepal.Length x Sepal.Width com regressão linear simples*", fig.width=5, fig.asp=.7}
iris |> 
  filter(Species == "versicolor") |>
  ggplot(aes(x=Petal.Length, y=Petal.Width)) +
  geom_smooth(method="lm", se=FALSE, formula="y~x") +
  geom_point() +
  labs(title = "Gráfico de dispersão Sepal.Length x Sepal.Width",
       subtitle = "Iris dataset")
```

\

É importante notar que a regressão apenas estima a variável target em função da feature preditora com base nos dados disponíveis. Não há na regressão inferência sobre relação de causa/efeito entre as variáveis (se uma causa a outra ou vice-versa ou se apenas ocorrem juntas).

Como se vê na figura, em geral os dados não caem exatamente na linha reta que foi estimada pela regressão. Então a equação dessa linha de regressão deve incluir um termo de erro explícito que representa essas diferenças conhecidas como resíduos. Além disso, entre os estatísticos convenciona-se denotar os valores ajustados ou valores estimados por $\hat{Y}$ (Y com um chapéu), assim como nos coeficientes e no resíduo. Isso indica que os coeficientes e o resíduo também são estimados (não conhecidos) e essa estimativa inclui incerteza, enquanto o valor verdadeiro (sem o chapéu) seria exato:

$$
\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1} X_i + \hat{\epsilon}_i
$$

A linha de regressão é ajustada de modo a minimizar a soma dos quadrados dos resíduos, ou seja, a diferença entre os valores reais e os valores previstos. A linha de regressão é a estimativa que minimiza a soma dos valores residuais quadrados, também chamada de soma residual dos quadrados (residual sum of squares) ou RSS:

$$
RSS = \sum_{i=1}^{n} (Y_i - \hat{Y_i})^2 = \sum_{i=1}^{n} (Y_i - \hat{\beta_0} - \hat{\beta_1} X_i)^2
$$

As estimativas de $\beta_0$ e $\beta_1$ são os valores que minimizam o RSS. O método de minimizar a soma dos resíduos quadrados RSS é denominado regressão de mínimos quadrados ou regressão de mínimos quadrados ordinários (OLS - ordinary least squares). É frequentemente atribuído a Carl Friedrich Gauss, o matemático alemão, mas foi publicado pela primeira vez pelo matemático francês Adrien-Marie Legendre em 1805.

Quando existem vários preditores, a equação é simplesmente estendida para acomodá-los em um regressão linear múltipla:

$$
\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X_1 + \hat{\beta_2} X_2 + \ldots + \hat{\beta_q} X_q + \epsilon
$$

Em vez de uma linha, tem-se um modelo linear – a relação entre cada coeficiente e sua variável (feature) é linear.

Todos os outros conceitos da regressão linear simples, como o ajuste por mínimos quadrados e a definição de valores ajustados e resíduos, estendem-se à configuração de regressão linear múltipla.

\
A [**regressão logística**]{.underline} é análoga à regressão linear com múltiplas variáveis, exceto que o resultado é [binário]{.underline}. Várias transformações são empregadas para converter o problema em algo no qual um modelo linear possa ser ajustado. A regressão logística é uma abordagem de modelo estruturado, em vez de uma abordagem centrada em dados. Devido à sua velocidade de processamento com menor custo computacional e sua rapidez na classificação de novos dados, é um método bastante adotado.

Os principais ingredientes para a regressão logística são a função de resposta logística (*logistic response function*) e o logit, no qual mapeia-se uma probabilidade (entre 0 e 1) para uma escala mais ampla, adequada para modelagem linear. O primeiro passo é pensar na variável de resultado não como um rótulo binário, mas como a probabilidade $p$ de que o rótulo seja “1”. Ingenuamente, podemos ficar tentados a modelar $p$ como uma função linear das variáveis preditoras:

$$
p = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q
$$

No entanto, ajustar esta função não garante que $p$ resulte em um número entre 0 e 1, como tem que acontecer com uma probabilidade. Então, é necessário modelar $p$ aplicando uma "função de resposta logística" ([*logistic response function*]{.underline}) aos preditores:

$$
p = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q)}}
$$

Essa transformação garante que $p$ permaneça entre 0 e 1.

Para tirar a expressão exponencial do denominador, pode-se expressar essa equação em termos de "chances" ou [*odds*]{.underline} em vez de probabilidade.

A chance, conceito familiar aos apostadores do mundo todo, é a razão entre “sucessos” (1) e “fracassos” (0). Na linguagem de probabilidade, "chances" são a probabilidade de um evento ocorrer dividida pela probabilidade de o evento não ocorrer. Por exemplo, se a probabilidade de um cavalo ganhar for $0,5$, a probabilidade de “não ganhar” é $(1 – 0,5) = 0,5$ e as chances são de 1 pra 1, então:

$$
Odds(Y=1) = \frac{p}{1-p}
$$

É possível obter a probabilidade a partir das chances usando o inverso da função de chances:

$$
p = \frac{Odds(Y=1)}{1 + Odds(Y=1)}
$$

Combinando isso com a [*logistic response function*]{.underline} vista anteriormente, tem-se que:

$$
Odds(Y=1) = e^{\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q}
$$

Finalmente, tirando o logaritmo natural de ambos os lados, obtém-se uma equação que é uma função linear dos preditores:

$$
log(Odds(Y=1)) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_q x_q
$$

A [função log-odds]{.underline}, também conhecida como [função logit]{.underline}, mapeia a probabilidade $p$ de $(0,1)$ para qualquer valor $(-\infty, +\infty)$. Assim o círculo de transformação se fecha, aplicando um modelo linear para prever uma probabilidade, que por sua vez pode ser mapeado para um rótulo de classe aplicando-se uma regra de corte – qualquer observação com uma probabilidade maior que o ponto de corte é classificado como 1.

```{r 5-3, echo=FALSE, fig.cap="*Gráfico de função logit que coloca uma probabilidade em uma escala aplicável a um modelo linear.*", fig.width=5, fig.asp=.7}
# Plot logit(p) x p
ggplot(data=tibble(x=seq(0.01, 0.99, by=0.01), 
                   y=log(seq(0.01, 0.99, by=0.01)/(1-seq(0.01, 0.99, by=0.01)))),
       aes(x=x, y=y)) +
  geom_line(color="blue") +
  labs(x="p", y="logit(p)")
```

\

A resposta na função de regressão logística é o log das probabilidades de um resultado binário de 1. Pretende-se extrair apenas o resultado binário, não o log das probabilidades, portanto, são necessários métodos estatísticos especiais para ajustar a equação.

\

# XXX Modelos de Classificação

**\
Com a base escolhida:**

\

## Etapas de modelagem

**Descreva as etapas necessárias para criar um modelo de classificação eficiente.**

No artigo *"To Explain or to Predict?"* ([Shmueli, 2010](#references)), o autor distingue entre o uso de modelos estatísticos para explicar causalidade ou projetar um processo ou sistema e examina as implicações das diferenças entre o objetivo de explicar causalidade (explicativo) versus projetar (preditivo) sobre o processo de modelagem.

Com base nas etapas descritas na seção "*2. Two Modeling Paths*" do artigo, um processo genérico de modelagem consiste em:

1.  Definir um objetivo

2.  Desenhar o estudo e coletar os dados

3.  Preparar os dados

4.  Analisar os dados (EDA)

5.  Escolher as variáveis

6.  Escolher os métodos

7.  Avaliar, validar e selecionar os modelos

8.  Aplicar o modelo e descrever resultados

\
Segundo Shmueli, modelagem preditiva e modelagem explicativa são frequentemente confundidos, mas a distinção entre as duas tem um grande impacto em cada etapa do processo de modelagem estatística e nas suas consequências.

Em muitos campos científicos, tais como economia, psicologia, educação e ciência do meio ambiente, os modelos estatísticos são usados quase exclusivamente para explicação causal. Em áreas como processamento de linguagem natural (NLP) e bioinformática, o foco está na previsão empírica com apenas uma relação superficial e indireta com a explicação causal. E, ainda, noutros campos de investigação, como a epidemiologia, a ênfase na explicação causal versus a previsão empírica é mais obscura.

Na [modelagem explicativa]{.underline} modelos estatísticos são aplicados a dados para testar uma hipótese de causa e efeito derivada de um modelo causal teórico. Nesses modelos, presume-se que um conjunto de fatores medidos pelas variáveis $X$ causa um efeito subjacente, medido pela variável $Y$. Os tipos de modelos estatísticos utilizados para testar hipóteses causais nas ciências sociais são quase sempre modelos baseados em associações aplicados a dados observados, sendo a regressão o método mais rotineiramente aplicado.

A justificativa para esta abordagem é que a própria teoria fornece a causalidade. Em outras palavras, o papel da teoria é muito forte e a confiança nos dados e na modelagem estatística ocorre estritamente sob a ótica do modelo teórico. Nesse tipo de modelagem, a inferência estatística leva a conclusões sobre o tamanho do efeito e significância estatística das hipóteses causais. Finalmente, as conclusões estatísticas levam a conclusões de pesquisa, muitas vezes acompanhadas de recomendações de políticas públicas.

[Modelagem preditiva]{.underline} é o processo de aplicação de um modelo estatístico ou algoritmo de mineração de dados com o propósito de prever novas ou futuras ocorrências. Especificamente, no caso da previsão determinística (Geisser, 1993, p. 31), o objetivo é prever o valor de saída $Y$ para novas observações, dados seus valores de entrada $X$. Esta definição também inclui a projeção de séries temporais, onde as observações até o momento $t$ (a entrada) são usadas para prever valores futuros no tempo $t + k,\ k > 0$ (a saída). Modelo preditivo é qualquer método que faz previsões, independentemente do método adotado e do tipo de resultado esperado: classificação ou regressão.

Por que deve-se diferenciar entre explicar e projetar? Porque os dados disponíveis não são representações exatas do processo ou sistema subjacente. A operacionalização de teorias em modelos estatísticos e dados mensuráveis cria uma disparidade entre a capacidade de explicar fenômenos conceitualmente e a capacidade de gerar previsões mensuráveis.

Tome-se como ilustração, uma teoria que postula que o fenômeno $X$ causa o fenômeno $Y$, através da função $F$, tal que $Y = F(X)$. $F$ é frequentemente representada por um diagrama, um conjunto de declarações qualitativas, um gráfico (e.g., um gráfico de oferta vs demanda) ou fórmulas matemáticas. As variáveis mensuráveis $x$ e $y$ são operacionalizações de $X$ e $Y$, respectivamente. A operacionalização de $F$ em um modelo estatístico $f$ , como $E(y) = f(x)$, é feita considerando $F$ sob a ótica do desenho do estudo teórico e de restrições práticas do contexto sistêmico, como padrões adotados em um mercado ou regulamentação existente. Como $F$ geralmente não é suficientemente detalhado para levar a um único $f$, muitas vezes um conjunto de modelos $f$ pode ser considerado.

No contexto preditivo, considera-se apenas $x$, $y$ e $f$.

A diferença surge porque o objetivo da modelagem explicativa é aproximar $f$ e $F$ o máximo possível para que a inferência estatística se aplique às hipóteses teóricas. Os dados $x,y$ são ferramentas para estimar $f$, que por sua vez são usados para testar as hipóteses causais. Em contraste, na modelagem preditiva as entidades de interesse são $x$ e $y$, e a função $f$ é usada como ferramenta para gerar boas previsões de novos valores de $y$. De fato, mesmo que a relação causal subjacente seja de fato $Y = F(X)$, é comum que uma função diferente de $\hat{f}(x)$ e dados diferentes de $x_i, ..., x_p$ possam gerar previsões melhores.

Assim, há quatro aspectos em que a diferença entre os dois objetivos de modelagem se manifestam:

1.  [Causa x Relação]{.underline}: Na modelagem explicativa $f$ representa uma função causal e assume-se que $x$ causa $y$. Na modelagem preditiva $f$ captura a relação entre $x$ e $y$.

2.  [Teoria x Dados]{.underline}: Na modelagem explicativa, $f$ é cuidadosamente construído com base em $F$ de forma a facilitar a interpretação da relação estimada entre $x$ e $y$ e o teste das hipóteses causais. Na modelagem preditiva, $f$ geralmente é construído a partir dos dados. A interpretabilidade da relação entre $x$ e $y$ não é necessária, embora às vezes a transparência de $f$ seja desejável.

3.  [Retrospectivo x Prospectivo]{.underline}: A modelagem preditiva é prospectiva, pois $f$ é construída para prever novas observações. Em contraste, a modelagem explicativa é retrospectiva, na medida em que $f$ é usada para testar um conjunto de hipóteses já existente.

4.  [Viés x Variabilidade]{.underline}: O erro de previsão esperado para uma nova observação pode ser decomposto em três partes: $EPE = Viés + Var(\hat{f}(x)) + Var(Y)$, onde o Viés é oriundo da má especificação do modelo $f$, a Variabilidade da Estimativa (o segundo componente) é oriundo da diferença entre a amostra de dados e a população total e o último componente é o resíduo que resta mesmo que o modelo tenha sido corretamente especificado e estimado. Na modelagem explicativa, o foco está em minimizar o Viés para obter a representação mais precisa da teoria subjacente. A modelagem preditiva procura minimizar a combinação de Viés e Variabilidade da Estimativa, podendo sacrificar a acurácia teórica para melhorar a acurácia empírica.

\

**(1) Definir um objetivo**

Esta é uma etapa auto-explicativa, mas ressalta-se que é importante estabelecer *a priori* se o objetivo é de natureza explicativa ou preditiva. A resposta a essa pergunta terá implicações em todas as etapas subsequentes do processo de modelagem.

\

**(2) Desenhar o estudo**

XXXXXXX

\

**(3) Preparar os dados**

XXXXXX

\

**(4) Analisar os dados (EDA)**

XXXXXX

\

**(5) Escolher as variáveis**

\

**(6) Escolher os métodos**

XXXXXX

\

**(7) Avaliar, validar e selecionar os modelos**

XXXXXX

\

**(8) Aplicar o modelo e descrever os resultados**

XXXXXXX

\

Embora não seja o foco deste artigo, um terceiro tipo de modelagem mencionado pelo autor, que é o mais comumente utilizado por estatísticos, é a [modelagem descritiva]{.underline}. Este tipo de modelagem visa resumir ou representar a estrutura de dados de forma compacta. Diferente modelagem explicativa, na modelagem descritiva a confiança em uma teoria causal subjacente está ausente ou incorporada de forma menos formal. Além disso, o foco está no nível mensurável e não no nível da construção teórica. Ao contrário da modelagem preditiva, a modelagem descritiva não visa a previsão. O ajuste de um modelo de regressão pode ser descritivo se for usado para capturar a associação entre as variáveis dependentes e independentes, e não para inferência causal ou para previsão. Mencionamos esse tipo de modelagem para evitar confusão com modelagem causal explicativa e preditiva, e também para destacar o diferentes abordagens de estatísticos e não estatísticos. Modelagem estatística descritiva, onde o propósito é capturar a estrutura subjacente dos dados, e que é o mais comumente desenvolvido dentro do campo de estatística, não é comumente usado para construção de teoria e testes em outras áreas de pesquisa científica.

\

## XXX Regressão logística

**Treine um modelo de regressão logística para realizar a classificação.**

```{r}
# library(glm)  # Logistic regression model
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo.?**

```{r}

```

\

## XXX Árvore de Decisão

**Treine um modelo de árvore de decisão para realizar a classificação.**

```{r}
# library(rpart)  # Decision Tree 
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**

```{r}

```

\

## XXX Random Forest

**Treine um modelo de random forest para realizar a classificação.**

```{r}
# library(ranger) # Random Forest 
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**

```{r}

```

\

## XXX Redes Neurais

**Treine um modelo de rede neural rasa para realizar a classificação.**

```{r}
# library(nnet, keras)   # Redes Neurais
```

\

**Qual a acurácia, a precisão, a recall e o f1-score do modelo?**

```{r}

```

\

# XXX Melhor modelo

**Em relação à questão anterior, qual o modelo deveria ser escolhido para uma eventual operação.**

XXXXXXXX

\

# XXX Deep Learning

**Descreva em suas palavras o que é Deep Learning.**

XXXXXXXX

\

# FIM

*Antes de fazer sua entrega, reúna todos os arquivos relativos ao seu Projeto de Disciplina em um único arquivo no formato .zip e poste no Moodle. Utilize o seu nome para nomear o arquivo, identificando também a disciplina, como no exemplo: “nomedoaluno_nomedadisciplina_pd.zip”.*

\

# Referências Bibliográficas {#references}

\

Bruce, P., Bruce, A. and Gedeck, P. (2020). "*Practical Statistics for Data Scientists : 50+ Essential Concepts Using R and Python."* Sebastopol: O’reilly Media, Incorporated. ISBN-13: 978-1492072942.

\

Geisser, S. (1993). *"Predictive Inference: An Introduction."* Chapman and Hall, Londres. [DOI: 10.1201/9780203742310](https://doi.org/10.1201/9780203742310)

\

Shmueli, G. (2010). "*To Explain or to Predict?*" *Statistical Science*, Institute of Mathematical Statistics [[online](https://projecteuclid.org/journals/statistical-science/volume-25/issue-3/To-Explain-or-to-Predict/10.1214/10-STS330.full)] v. 25, n. 3, p. 289–310. [DOI: 10.1214/10-STS330]
